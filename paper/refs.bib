@article{Arras2017,
    author = {Arras, Leila AND Horn, Franziska AND Montavon, Grégoire AND Müller, Klaus-Robert AND Samek, Wojciech},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {"What is relevant in a text document?": An interpretable machine learning approach},
    year = {2017},
    month = {08},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0181142},
    pages = {1-23},
    abstract = {Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text’s category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications.},
    number = {8},
    doi = {10.1371/journal.pone.0181142}
}


@BOOK{fallows,
  TITLE = {A Complete Dictionary of Synonyms and Antonyms},
  SUBTITLE = {or, Synonyms and Words of Opposite Meaning},
  AUTHOR = {Samuel Fallows},
  YEAR = {1898}, 
  URL = {http://www.gutenberg.org/ebooks/51155},
  PUBLISHER = {Digital Version by Steve Wood (2016) for Project Gutenberg}
}

@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}

@inproceedings{McAuley2013,
author = {McAuley, Julian and Leskovec, Jure},
year = {2013},
month = {05},
booktitle = {International World Wide Web Conference}
pages = {897-908},
title = {From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews},
doi = {10.1145/2488388.2488466}
}

@inproceedings{Almeida2011,
author = {Almeida, Tiago and Gomez Hidalgo, Jose and Yamakami, Akebo},
year = {2011},
month = {01},
booktitle = {Proceedings of the 2011 ACM Symposium on Document Engineering}
pages = {259-262},
title = {Contributions to the study of SMS spam filtering: new collection and results.}
}

@article{Go2009,
author = {Go, Alec and Bhayani, Richa and Huang, Lei},
year = {2009},
month = {01},
pages = {},
title = {Twitter sentiment classification using distant supervision},
volume = {},
journal = {CS224N project report, Stanford}
}


@ONLINE{xemp,
  AUTHOR =        {{DataRobot Inc.}},
  TITLE =         {XEMP Prediction Explanations with DataRobot},
  MONTH =         {July},
  YEAR  =         {2019},
  URL   =         {https://www.datarobot.com/resources/xemp-prediction-explanations/}
}

